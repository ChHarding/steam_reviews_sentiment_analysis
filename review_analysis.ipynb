{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests pandas seaborn matplotlib plotly nbformat scipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # pip install requests    \n",
    "import pandas as pd # pip install pandas\n",
    "import seaborn as sns # pip install seaborn\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "import plotly.express as px  # pip install plotly\n",
    "\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "import time \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set base name for the file\n",
    "base_name = << your game here >>\n",
    "\n",
    "extended_file = f'reviews_{base_name}_extended.csv'\n",
    "\n",
    "# if needed make a new folder of the base name\n",
    "if not os.path.exists(base_name):\n",
    "   print(f'Missing folder {base_name}')\n",
    "else:\n",
    "    # prepend that folder to all file names\n",
    "\n",
    "    extended_file = f'{base_name}/{extended_file}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fully processed CSV file\n",
    "df = pd.read_csv(extended_file)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2 columns to the dataframe one for the number of sentences and one for avg. number of words per sentence\n",
    "df['num_sentences'] = df['review'].apply(lambda x: len(x.rstrip(\". \").split(\".\")))\n",
    "df['avg_words_per_sentence'] = df['review'].apply(lambda x: sum([len(s.split()) for s in x.rstrip(\". \").split(\".\")]) / len(x.rstrip(\". \").split(\".\")))\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics of numeric data in the dataset\n",
    "# CH note that all reviews now are listed as unique i.e. no duplicates\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH print out the timespan of the reviews\n",
    "# this is useful for dweciding what timespand to aggregate to\n",
    "print(df['timestamp_created'].min(), df['timestamp_created'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH aggregate means of values over time (monthly)\n",
    "df_agg  = df.copy() \n",
    "df_agg['timestamp_created'] = pd.to_datetime(df_agg['timestamp_created']) # make python datetime object\n",
    "df_agg.set_index('timestamp_created', inplace=True) # set index to timestamp_created\n",
    "\n",
    "# drop review column as it is not numeric\n",
    "df_agg.drop(columns=['review'], inplace=True)\n",
    "\n",
    "# resample all numeric columns to biweekly\n",
    "#df_agg = df_agg.resample('14D').mean() # resample all numeric columns to monthly\n",
    "\n",
    "# resample all numeric columns to monthly\n",
    "df_agg = df_agg.resample('MS').mean() # resample all numeric columns to monthly\n",
    "\n",
    "# resample all numeric columns to 3 month\n",
    "#df_agg = df_agg.resample('3MS').mean() # resample all numeric columns to 6 month\n",
    "\n",
    "# resample all numeric columns to 6 month\n",
    "#df_agg = df_agg.resample('6MS').mean() # resample all numeric columns to 6 month\n",
    "\n",
    "df_agg.reset_index(inplace=True) # reset index to make timestamp_created a column again\n",
    "df_agg['timestamp_created'] = df_agg['timestamp_created'].dt.strftime('%Y-%m') # format timestamp_created\n",
    "display(df_agg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def plot_over_time_sns(columns, df, logy=False):\n",
    "    df = df[columns + ['timestamp_created']]\n",
    "    # Melting the DataFrame\n",
    "    df_melted = df.melt('timestamp_created', var_name='variable', value_name='value')\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    sns.lineplot(data=df_melted, x='timestamp_created', y='value', hue='variable')\n",
    "    plt.xlim(df['timestamp_created'].min(), df['timestamp_created'].max())\n",
    "    if logy:\n",
    "        plt.yscale('log')\n",
    "\n",
    "def plot_over_time_plotly(columns, df, logy=False):\n",
    "    df = df[columns + ['timestamp_created']]\n",
    "    # Melting the DataFrame\n",
    "    df_melted = df.melt('timestamp_created', var_name='variable', value_name='value')\n",
    "        # Assuming df_melted is already created and contains 'timestamp_created', 'variable', and 'value' columns\n",
    "    fig = px.line(df_melted, x='timestamp_created', y='value', color='variable', log_y=logy)\n",
    "\n",
    "    # Update layout if necessary, for example, setting the x-axis range\n",
    "    fig.update_layout(xaxis_range=[df_melted['timestamp_created'].min(), df_melted['timestamp_created'].max()])\n",
    "\n",
    "    if logy:\n",
    "        fig.update_yaxes(type='log')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot aggregated values over time using variables that are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_time_plotly(['positive_score', 'negative_score', 'objective_score'], df_agg, logy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_time_plotly(['word_count', 'adj_count', 'verb_count', 'noun_count', 'adv_count'], df_agg, logy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_time_plotly(['author_vote', 'other_votes', 'votes_funny', 'comment_count'], df_agg, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- seems may 2017 had a lot of fun :)  (16 million votes!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Numerical Variables\n",
    "# Visualize the distribution of numerical variables using histograms and boxplots.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Histogram for numerical columns\n",
    "\n",
    "dfs = df[['positive_score', 'negative_score', 'objective_score']]\n",
    "dfs.hist(bins=100, figsize=(20, 10))\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for numerical columns\n",
    "#plt.figure(figsize=(15, 10))\n",
    "#sns.boxplot(data=df)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of a column with a specific x limit\n",
    "def histo_xlim(column, xlimit):\n",
    "    df[column].hist(bins=200, figsize=(10, 3))\n",
    "    plt.title(f'Histogram of {column}')\n",
    "    plt.xlim([0, xlimit])  # Limit the x-axis to 500\n",
    "    plt.show()\n",
    "\n",
    "histo_xlim('word_count', 300)\n",
    "histo_xlim('adj_count', 50)\n",
    "histo_xlim('verb_count', 200)\n",
    "histo_xlim('noun_count', 200)\n",
    "histo_xlim('adv_count', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentages of adj, verb, noun, adv to word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to df that describe the ratio of adj, verb, noun, adv to word count\n",
    "# i.e. this is the percentage of each type of word in the review\n",
    "\n",
    "\n",
    "df['adj percentage'] = df['adj_count'] / df['word_count'] * 100\n",
    "df['verb percentage'] = df['verb_count'] / df['word_count'] * 100\n",
    "df['noun percentage'] = df['noun_count'] / df['word_count'] * 100\n",
    "df['adv percentage'] = df['adv_count'] / df['word_count']  * 100\n",
    "\n",
    "dfr = df[['adj percentage', 'verb percentage', 'noun percentage', 'adv percentage']]\n",
    "axes = dfr.hist(bins=100, figsize=(10, 5))\n",
    "\n",
    "# get the mean of the percentage of adj, verb, noun, adv\n",
    "for c in ['adj percentage', 'verb percentage', 'noun percentage', 'adv percentage']:\n",
    "    print(f\"{c} mean: {df[c].mean()}\")\n",
    "\n",
    "# how many reviews have < 5% percentage of adj, verb, noun, adv ?\n",
    "print(\"\\nReviews with < 1% percentage of adj, verb, noun, adv\")\n",
    "for c in ['adj percentage', 'verb percentage', 'noun percentage', 'adv percentage']:\n",
    "    print(f\"{c} < 1%: {len(df[df[c] < 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun with combinations of percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the row indices of the review with the lowest percentage of adj, verb, noun, adv and print the review\n",
    "for c in ['adj percentage', 'verb percentage', 'noun percentage', 'adv percentage']:\n",
    "    print(f\"Review with lowest {c}: {min(df[c])}\")\n",
    "    print(df.loc[df[c].idxmin()]['review'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the row indices of the review with the higher percentage of adj, verb, noun, adv and print the review and the percent\n",
    "for c in ['adj percentage', 'verb percentage', 'noun percentage', 'adv percentage']:\n",
    "    print(f\"Review with highest {c}: {max(df[c])}\")\n",
    "    print(df.loc[df[c].idxmax()]['review'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find reviews with a certain mix of percentages\n",
    "- the below mix was given by CoPilot as for advanced reading ability (check?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out row indices of reviews that have:\n",
    "# 1) 28 - 32 % nouns and\n",
    "# 2) 8 - 12% verbs and\n",
    "# 3) 8 - 12% adjectives and \n",
    "# 4) 1 - 5% adverbs\n",
    "\n",
    "good_noun_perc = set(df[(df['noun percentage'] >= 28) & (df['noun percentage'] <= 32)].index.tolist())\n",
    "good_verb_perc = set(df[(df['verb percentage'] >= 8) & (df['verb percentage'] <= 12)].index.tolist())\n",
    "good_adj_perc = set(df[(df['adj percentage'] >= 8) & (df['adj percentage'] <= 12)].index.tolist())\n",
    "good_adv_perc = set(df[(df['adv percentage'] >= 1) & (df['adv percentage'] <= 5)].index.tolist())\n",
    "\n",
    "# print length of sets\n",
    "print(f\"good_noun_perc: {len(good_noun_perc)}\")\n",
    "print(f\"good_verb_perc: {len(good_verb_perc)}\")\n",
    "print(f\"good_adj_perc: {len(good_adj_perc)}\")\n",
    "print(f\"good_adv_perc: {len(good_adv_perc)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find reviews that cover 2 or 3 of the 4 categories as good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# List of all sets\n",
    "sets = [good_noun_perc, good_verb_perc, good_adj_perc, good_adv_perc]\n",
    "set_names = ['good_noun_perc', 'good_verb_perc', 'good_adj_perc', 'good_adv_perc']\n",
    "\n",
    "# Generate all 2-set combinations and print their intersection sizes\n",
    "for (set1, set2), (name1, name2) in zip(combinations(sets, 2), combinations(set_names, 2)):\n",
    "    intersection_length = len(set1 & set2)\n",
    "    print(f\"Intersection length of {name1} and {name2}: {intersection_length}\")\n",
    "\n",
    "# Generate and print 3-set combinations and their intersection sizes\n",
    "for (set1, set2, set3), (name1, name2, name3) in zip(combinations(sets, 3), combinations(set_names, 3)):\n",
    "    intersection_length = len(set1 & set2 & set3)\n",
    "    print(f\"Intersection length of {name1}, {name2}, and {name3}: {intersection_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index for Intersection length of good_noun_perc and good_verb_perc\n",
    "good_verb_noun_adv = good_verb_perc & good_noun_perc  \n",
    "print(f\"good_verb_adj_adv: {len(good_verb_noun_adv)}\")\n",
    "\n",
    "# print reviews of good_verb_adj_adv \n",
    "for i in good_verb_noun_adv:\n",
    "    print(df.loc[i]['review'])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index for Intersection length of good_verb_perc, good_adj_perc, and good_adv_perc\n",
    "good_verb_adj_adv = good_verb_perc & good_adj_perc & good_adv_perc\n",
    "print(f\"good_verb_adj_adv: {len(good_verb_adj_adv)}\")\n",
    "\n",
    "# print reviews of good_verb_adj_adv \n",
    "for i in good_verb_adj_adv:\n",
    "    print(df.loc[i]['review'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many reviews have nouns as the most use type of words, etc. ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to df add a column that indicates which of adj, verb, noun, adv is the biggest \n",
    "# encode with \"adj_count\", \"verb_count\", \"noun_count\", \"adv_count\"\n",
    "df['POS percentage'] = df[['adj percentage', 'verb percentage', 'noun percentage', 'adv percentage']].idxmax(axis=1)\n",
    "\n",
    "# show the distribution of the POS percentage\n",
    "df['POS percentage'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how row ids for reviews  with the highest percentage for adj and adv\n",
    "print(\"highest type of words is adj\")\n",
    "print(df.loc[df['adj percentage'].idxmax()]['review'])\n",
    "print(\"\\nhighest type of words is adj\")\n",
    "print(df.loc[df['adv percentage'].idxmax()]['review'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE plots\n",
    "- 2D histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting KDE plots\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# KDE plot for positive sentiment score vs adjective count\n",
    "sns.kdeplot(data=df, x='adj_count', y='positive_score', fill=True, cmap=\"Blues\", thresh=0.05)\n",
    "plt.title('KDE Plot: Adjective Count vs Positive Sentiment Score')\n",
    "plt.xlabel('Adjective Count')\n",
    "plt.ylabel('Positive Sentiment Score')\n",
    "plt.xlim(0, 50) # limit x-axis to 0-600\n",
    "plt.ylim(0, 0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# KDE plot for negative sentiment score vs adjective count\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.kdeplot(data=df, x='adj_count', y='negative_score', fill=True, cmap=\"Reds\", thresh=0.05)\n",
    "plt.title('KDE Plot: Adjective Count vs Negative Sentiment Score')\n",
    "plt.xlabel('Adjective Count')\n",
    "plt.ylabel('Negative Sentiment Score')\n",
    "#plt.xlim(0, 600)\n",
    "#plt.ylim(0, 0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KDE plot for objective sentiment score vs adjective count\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.kdeplot(data=df, x='adj_count', y='objective_score', fill=True, cmap=\"Greens\", thresh=0.05)\n",
    "plt.title('KDE Plot: Adjective Count vs Objective Sentiment Score')\n",
    "plt.xlabel('Adjective Count')\n",
    "plt.ylabel('Objective Sentiment Score')\n",
    "plt.xlim(0, 700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KDE plot for objective sentiment score vs adjective count\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.kdeplot(data=df, x='adj_count', y='objective_score', fill=True, cmap=\"Greens\", thresh=0.05)\n",
    "plt.title('KDE Plot: Adjective Count vs Objective Sentiment Score')\n",
    "plt.xlabel('Adjective Count')\n",
    "plt.ylabel('Objective Sentiment Score')\n",
    "plt.xlim(0, 700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here for correlations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "# Ignore UserWarning about figure layout\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='seaborn.axisgrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coeffcient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is from 574 Lecture 41-Data Science\n",
    "# visualizing the correlation coefficient\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "r2 = numeric_df.corr(method='pearson')   # pearson is the standard method of calculation the goodness of fit\n",
    "display(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the correlation pairs that have the 10 absolute highest correlation values\n",
    "# the diagonal is always 1.0\n",
    "s = r2.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)\n",
    "so = so[so != 1.0]  # remove diagonal\n",
    "so = so[::2]  # remove duplicates\n",
    "#so = so[0:20]  # get the top 6\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Split the Series into positive and negative correlations\n",
    "positive_correlations = so[so > 0]\n",
    "negative_correlations = so[so < 0]\n",
    "\n",
    "# Print positive correlations from 1.0 to 0\n",
    "print(\"Positive Correlations from 1.0 to 0:\")\n",
    "print(positive_correlations)  # This reverses the positive correlations if needed\n",
    "\n",
    "# Print negative correlations from -1.0 to 0\n",
    "print(\"\\nNegative Correlations from -1.0 to 0:\")\n",
    "print(negative_correlations[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "r2s = numeric_df.corr(method='spearman')   # spearman is a rank-ordering method\n",
    "display(r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but for spearman rank corr.\n",
    "s = r2s.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)\n",
    "so = so[so != 1.0]  # remove diagonal\n",
    "so = so[::2]  # remove duplicates\n",
    "#so = so[0:20]  # get the top 6\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Split the Series into positive and negative correlations\n",
    "positive_correlations = so[so > 0]\n",
    "negative_correlations = so[so < 0]\n",
    "\n",
    "# Print positive correlations from 1.0 to 0\n",
    "print(\"Positive Correlations from 1.0 to 0:\")\n",
    "print(positive_correlations)  # This reverses the positive correlations if needed\n",
    "\n",
    "# Print negative correlations from -1.0 to 0\n",
    "print(\"\\nNegative Correlations from -1.0 to 0:\")\n",
    "print(negative_correlations[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step: correlation matrix between all values. However, first I need to get the R2s.\n",
    "ax1, fig =  plt.subplots(figsize= (15, 15))\n",
    "sns.heatmap(abs(r2), \n",
    "            annot = True, \n",
    "            fmt=\".1f\"); # show numbers, but with 1 digit only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the 574 Lecture 41-Data Science\n",
    "# scatterplot of votes_funny vs positive_score with regression line\n",
    "ax1, fig =  plt.subplots(figsize= (10, 10))\n",
    "plt.close(plt.gcf()) # I'm unclear why this is needed here but whatevs\n",
    "\n",
    "x = \"num_sentences\"\n",
    "y = \"word_count\"\n",
    "\n",
    "\n",
    "p = sns.lmplot(data=df, x=x, y=y, height=10, aspect=1); \n",
    "\n",
    "#limit the x and y axes\n",
    "p.set(xlim=(0, 200), ylim=(0, 1000));\n",
    "#p.set(xscale=\"linear\", yscale=\"log\");\n",
    "#p.set_axis_labels(\"Number of Votes funny\", \"Number of upvotes by others\");\n",
    "#p.set(title='Votes_funny vs positive_score with regression line');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CH: there definitifly an outlier!\n",
    "- also: x should be log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the 574 Lecture 41-Data Science\n",
    "# scatterplot of votes_funny vs positive_score with regression line\n",
    "ax1, fig =  plt.subplots(figsize= (10, 10))\n",
    "plt.close(plt.gcf()) # I'm unclear why this is needed here but whatevs\n",
    "\n",
    "x = \"num_sentences\"\n",
    "y = \"word_count\"\n",
    "\n",
    "# make a df with no outliers\n",
    "dfnu = df[(df[x] < 10000)]\n",
    "\n",
    "p = sns.lmplot(data=dfnu, x=x, y=y, height=10, aspect=1); \n",
    "p.set(xscale=\"log\", yscale=\"linear\");\n",
    "#p.set_axis_labels(\"Number of Votes funny\", \"Number of upvotes by others\");\n",
    "#p.set(title='Votes_funny vs positive_score with regression line');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the 574 Lecture 41-Data Science\n",
    "# scatterplot of votes_funny vs positive_score\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (10, 10))\n",
    "\n",
    "x = \"other_votes\"\n",
    "y = \"weighted_vote_score\"\n",
    "\n",
    "sns.scatterplot(data=df, x=x, y=y, ax=ax)\n",
    "ax.set(title=f'{x} vs {y}', xlabel=x, ylabel=y);\n",
    "\n",
    "# set both axis to log\n",
    "ax.set_xscale('log');\n",
    "#ax.set_yscale('log');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CH: given that r2 is based on a linear relationship and this is more of a log relationship, no wonder r2 is pretty low!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create interactive scatterplots with plotly\n",
    "- plotly can show values on mouse-over so we could look at the review for it but those can be very long and are displayed in one line by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shortened multiline version of the review text\n",
    "# as plotly is HTML based we need o use <br> for line breaks, not \\n\n",
    "\n",
    "multiline_reviews = []  # Initialize the list here to ensure it's empty before starting the loop\n",
    "\n",
    "for review in df['review']:\n",
    "    words = review.split()\n",
    "    review_lines = []\n",
    "    for i in range(0, len(words), 20):\n",
    "        review_lines.append(' '.join(words[i:i+20]))\n",
    "    review_lines = review_lines[:10]  # Limit to 10 lines\n",
    "    multiline_reviews.append('<br>'.join(review_lines))\n",
    "\n",
    "df['reviewML'] = multiline_reviews  # Now, the length should match the DataFrame's index\n",
    "\n",
    "# show the first review\n",
    "display(df['reviewML'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also use colors (red/green) to show if a review was up or downvoted by its reviewer\n",
    "- We can leave the outlier in as we can zoom in with plotly!\n",
    "- \"other_votes\" (how many other users upvoted this review?) vs weighted_vote_score (how many found it __helpful__?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot using plotly\n",
    "#x = \"other_votes\"\n",
    "#y = \"weighted_vote_score\"\n",
    "\n",
    "x = \"num_sentences\"\n",
    "y = \"word_count\"\n",
    "\n",
    "# add a column author_vote_cat that is \"up\" where author is 1 and \"down\" where author is 0\n",
    "# this b/c for color_discrete_map we need a column with strings\n",
    "df[\"author_vote_cat\"] = df[\"author_vote\"].map({1: \"up\", 0: \"down\"})\n",
    "\n",
    "colr = \"author_vote_cat\"\n",
    "\n",
    "fig = px.scatter(df, x=x, y=y, log_x=True, #log_y=True, \n",
    "                 #title='Votes_funny vs positive_score',\n",
    "                 #labels={'votes_funny': 'Number of Votes funny', 'other_votes': 'Number of upvotes by others'},\n",
    "                 hover_data=\"reviewML\" ,    # add hover data\n",
    "                 color=colr,  # column to use for color\n",
    "                 color_discrete_map={\"up\":\"green\", \"down\":\"red\"}\n",
    "                 )\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many user found the review funny vs how may users left any of the other voting types that are possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"votes_funny\"\n",
    "y = \"other_votes\"\n",
    "\n",
    "x = \"avg_words_per_sentence\"  \n",
    "y = \"num_sentences\"\n",
    "\n",
    "# add a column author_vote_cat that is \"up\" where author is 1 and \"down\" where author is 0\n",
    "# this b/c for color_discrete_map we need a column with strings\n",
    "df[\"author_vote_cat\"] = df[\"author_vote\"].map({1: \"up\", 0: \"down\"})\n",
    "\n",
    "colr = \"author_vote_cat\"\n",
    "\n",
    "# scatterplot using plotly\n",
    "fig = px.scatter(df, x=x, y=y, log_x=False, log_y=False, \n",
    "                 #title='Votes_funny vs positive_score',\n",
    "                 #labels={'votes_funny': 'Number of Votes funny', 'other_votes': 'Number of upvotes by others'},\n",
    "                 hover_data=\"reviewML\" ,    # add hover data\n",
    "                 color=colr,  # column to use for color\n",
    "                 color_discrete_map={\"up\":\"green\", \"down\":\"red\"}\n",
    "                 )\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
